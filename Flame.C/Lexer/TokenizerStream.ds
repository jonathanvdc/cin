using System;
using System.Collections.Generic;
using System.Text;
using Flame.Compiler;
using Flame.C.Preprocessor;

namespace Flame.C.Lexer
{
	public class TokenizerStream : ITokenStream
	{
		public const this(set ITokenStream Stream)
		{
			Initialize();
		}

		private void Initialize()
		{
			this.tokens = new List<Token>();

			this.keywords = new Dictionary<string, TokenType>();
			this.keywords["false"] = TokenType.FalseLiteral;
			this.keywords["true"] = TokenType.TrueLiteral;
			this.keywords["auto"] = TokenType.AutoKeyword;
			this.keywords["if"] = TokenType.IfKeyword;
			this.keywords["else"] = TokenType.ElseKeyword;
			this.keywords["while"] = TokenType.WhileKeyword;
			this.keywords["sizeof"] = TokenType.SizeOfKeyword;
			this.keywords["for"] = TokenType.ForKeyword;
			this.keywords["return"] = TokenType.ReturnKeyword;
			this.keywords["struct"] = TokenType.StructKeyword;
			this.keywords["union"] = TokenType.UnionKeyword;
			this.keywords["enum"] = TokenType.EnumKeyword;
			this.keywords["typedef"] = TokenType.TypedefKeyword;
			this.keywords["inline"] = TokenType.InlineKeyword;
			this.keywords["const"] = TokenType.ConstKeyword;
			this.keywords["static"] = TokenType.StaticKeyword;
			this.keywords["null"] = TokenType.NullKeyword;
			this.keywords["break"] = TokenType.BreakKeyword;
			this.keywords["continue"] = TokenType.ContinueKeyword;
			this.keywords["do"] = TokenType.DoKeyword;
			this.keywords["unsigned"] = TokenType.UnsignedKeyword;
			this.keywords["signed"] = TokenType.SignedKeyword;
			this.keywords["long"] = TokenType.LongKeyword;
			this.keywords["short"] = TokenType.ShortKeyword;
			this.keywords["char"] = TokenType.CharKeyword;
			this.keywords["void"] = TokenType.VoidKeyword;
			this.keywords["int"] = TokenType.IntKeyword;
			this.keywords["float"] = TokenType.FloatKeyword;
			this.keywords["double"] = TokenType.DoubleKeyword;
			this.keywords["_Generic"] = TokenType.GenericKeyword;
			this.keywords["default"] = TokenType.DefaultKeyword;
			this.keywords["case"] = TokenType.CaseKeyword;
			this.keywords["switch"] = TokenType.SwitchKeyword;
			this.keywords["sizeof"] = TokenType.SizeOfKeyword;
			this.keywords["typeof"] = TokenType.TypeOfKeyword;
			this.keywords["__typeof__"] = TokenType.TypeOfKeyword;
		}

		public ITokenStream Stream { const get; private set; }

		private List<Token> tokens;
		private int currentIndex;

		private Dictionary<string, TokenType> keywords;

		private Token ParseNextToken()
		{
			var token = Stream.Next();

			if (token.Type == TokenType.Identifier && this.keywords.ContainsKey(token.TokenValue))
			{
				token = new Token(this.keywords[token.TokenValue], token.TokenValue, token.Location);
			}

			tokens.Add(token);
			return token;
		}

		#region ITokenStream Implementation

		private Token TokenAt(int Index)
		{
			while (tokens.Count < Index + 1)
			{
				var token = ParseNextToken();
				if (token.Type == TokenType.EndOfFile)
					return token;
			}
			return tokens[Index];
		}

		public Token Next()
		{
			var token = TokenAt(currentIndex);
			if (token.Type != TokenType.EndOfFile)
				currentIndex++;
			return token;
		}

		public void Seek(TokenIdentifier Identifier)
		{
			currentIndex = Identifier.Identifier;
		}

		public TokenIdentifier CurrentPosition
		{
			const get return new TokenIdentifier(currentIndex);
		}

		public const PeekToken Peek(TokenIdentifier Position)
		{
			return new PeekToken(Position.Identifier + 1, TokenAt(Position.Identifier));
		}

		public void Reset()
		{
			currentIndex = 0;
		}

		#endregion
	}
}
