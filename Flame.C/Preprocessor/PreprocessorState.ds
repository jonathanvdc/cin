using System;
using System.Collections.Generic;
using System.Text;
using Flame.Compiler;
using Flame.C.Lexer;

namespace Flame.C.Preprocessor
{
    public class PreprocessorState
    {
        public const this(set PreprocessorEnvironment Environment, ISourceFile File)
        {
            this.defs = new Dictionary<string, DefineDirective>();
            this.Includes = new IncludeManager(File);
        }
        public const this(set PreprocessorEnvironment Environment, set IncludeManager Includes)
        {
            this.defs = new Dictionary<string, DefineDirective>();
        }

        public PreprocessorEnvironment Environment { const get; private set; }
        public IncludeManager Includes { const get; private set; }

        private Dictionary<string, DefineDirective> defs;
        public [DefineDirective] Definitions { const get return defs.Values; }

        public void Define(DefineDirective Directive)
        {
            defs[Directive.Name] = Directive;
        }
        public void Undefine(string Name)
        {
            if (defs.ContainsKey(Name))
            {
                defs.Remove(Name);
            }
        }

        public const DefineDirective GetDefinition(string Name)
        {
            if (defs.ContainsKey(Name))
            {
                return defs[Name];
            }
            return null;
        }

        public const bool IsDefined(string Name)
        {
            return defs.ContainsKey(Name);
        }

        public TokenStreamBuilder ExpandDefinition(string Name)
        {
            var def = GetDefinition(Name);
            if (def == null)
            {
                return new TokenStreamBuilder();
            }
            else
            {
                return Expand(new MemoryTokenStream(def.Body.Substitute(new Token[][] { }))); 
            }
        }

        public TokenStreamBuilder Expand(ITokenStream Reader)
        {
            var preprocessor = new PreprocessorInstance(Reader, this);
            preprocessor.Process();
            return preprocessor.Builder;
        }
        public TokenStreamBuilder Expand(SourceChunk Chunk)
        {
            var chunkReader = new ChunkReader(Chunk);
            return Expand(chunkReader);
        }
        public TokenStreamBuilder Expand(ISourceReader Reader)
        {
            var tokenizer = new PreprocessorTokenizerStream(Reader);
            return Expand(tokenizer);
        }
        public TokenStreamBuilder Expand(ISourceDocument Document)
        {
            var text = Document.Source;
            var reader = new ChunkReader(new SourceChunk(text, new SourceLocation(Document, 0, text.Length)));
            return Expand(reader.PreprocessCharacters(Environment.Log));
        }
    }
}
